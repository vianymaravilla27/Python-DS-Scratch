{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de Hipotesis <br>\n",
    "Vamos a utilizar la aproximacion binomial con la prueba de hipotesis $ H~A $ Y $ H O $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def normal_cdf(x, mu =0,sigma=1):\n",
    "    return(1+ math.erf((x-mu)/math.sqrt(2)/sigma)) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.539827837277029"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_cdf(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normal_cdf(p , mu=0,sigma=1,tolerance=0.00001):\n",
    "    #busca aproximar la inversa usando busqueda binaria\n",
    "\n",
    "    #si no es estandar, computa estandar y reescala\n",
    "    if mu != 0 or sigma != 1:\n",
    "        return mu + sigma * inverse_normal_cdf(p,tolerance=tolerance)\n",
    "    low_z, low_p = -10.0,0 #normal cdf(-10) es muy cerca a 0\n",
    "    hi_z , hi_p = 10.0,1    #normal cdf(10) es muy cerca a 1\n",
    "    while hi_z - low_z > tolerance:\n",
    "        mid_z = (low_z + hi_z) / 2 #consideren el punto medio\n",
    "        print (mid_z)\n",
    "        mid_p = normal_cdf(mid_z)   #y el valor de cdf aca\n",
    "        print (mid_p)\n",
    "        if mid_p < p:\n",
    "            #puntomedio aun es muy bajo busca arriba de el\n",
    "            print(\"here 1\")\n",
    "            low_z,low_p = mid_z,mid_p\n",
    "        elif mid_p > p :\n",
    "            #punto medio aun es muy alto , buscar abajo de el\n",
    "            hi_z,hi_p = mid_z,mid_p\n",
    "            print(\"here 2\")\n",
    "        else:\n",
    "            break\n",
    "        return mid_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "inverse_normal_cdf(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09000000000000001, 0.09486832980505137)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def normal_aproximation_to_binomial(n,p):\n",
    "    #Busca mu y sigma que corresponde a la binomial (n,p)\n",
    "    mu = p * n\n",
    "    sigma = math.sqrt(p * (1-p) * n)\n",
    "    return mu, sigma\n",
    "\n",
    "normal_aproximation_to_binomial(0.1,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La normal cdf_is_the_probability la variable es debajo del limite\n",
    "normal_probability_below = normal_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta arriba el limite si eno pertenece por debajo del limite\n",
    "def normal_probability_above(lo, mu=0,sigma=1):\n",
    "    return 1 - normal_cdf(lo,mu,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta entre si es menor que hi, pero no menor que lo\n",
    "def normal_probability_between(lo,hi,mu=0,sigma = 1):\n",
    "    return normal_cdf(hi,mu,sigma) - normal_cdf(lo,mu,sigma)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  normal_probability_outside(lo,hi,mu=0,sigma=1):\n",
    "    return 1 - normal_probability_between(lo,hi,mu,sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_upper_bound(probability, mu=0,sigma=1):\n",
    "    # regresa z para cada P(Z<=Z) = probabilidad\n",
    "    return inverse_normal_cdf(probability,mu,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_lower_bound(probability,mu=0,sigma=1):\n",
    "    #regresa z para cada P (Z>=Z) = probabilidad\n",
    "    return inverse_normal_cdf(1-probability,mu,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_two_sided_bounds(probability,mu=0,sigma=1):\n",
    "    #regresa el simetrico ( cerca de la media) limite\n",
    "    #que contiene la probabilidad especifica\n",
    "    tail_probability = (1-probability) / 2\n",
    "    #arriba de los limites debe tener la cola de probabilidad arriba de \n",
    "    upper_bound = normal_lower_bound(tail_probability,mu,sigma)\n",
    "    #lower limite debe tener la cola de probabilidad abajo de\n",
    "    lower_bound = normal_upper_bound(tail_probability,mu,sigma)\n",
    "\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos de hacer nuestra prueba de hipotesis simple con una moneda donde haremos el intento  con mu = 0 , sigma = 0 y la aproximacion normal binomial esta dada por 1000 intentos con probabilidad 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0,sigma_0 = normal_aproximation_to_binomial(1000,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5\n",
      "here 1\n",
      "0.0\n",
      "0.5\n",
      "here 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500.0, 500.0)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_two_sided_bounds(0.95,mu_0,sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer con el codigo del libro me arrojo algun especie de error, que raro. En fin continuare con algo que buscare en internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba Z \n",
    "### Utilizando libreria stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fórmula anterior se puede entender como:Media de la muestra: la media de la población (es decir, la distancia entre ellos) dividida por una desviación estándar de la muestra, el resultado es que la distancia entre ellos es igual a varias veces la desviación estándar., Si es mayor que 2, es decir, la desviación excede 2 veces la desviación estándar, cae en el dominio de rechazo. La desviación estándar de esta distribución media viene dada por el teorema del límite central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo sencillo: muestra de cinco lotes de lecheTemperatura muy fríaSon $  - 0.547, -0.532, -0.548, -0.531, -0.535  $, y la temperatura del punto de congelación de la leche natural obedece a una distribución normal,El valor medio es -0,545 ℃, la desviación estándar es 0,008 ℃, Si se mezcla agua, la temperatura del punto de congelación aumentará y tenderá gradualmente a 0 ℃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La estadística Z es 1.788854381999821\n",
      "El valor p es 0.07363827012030438\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Establezca la temperatura del punto de congelación de 5 lotes de leche muestreados\n",
    "a = np.array([-0.547, -0.532, -0.548, -0.531, -0.535])\n",
    "\n",
    "# Establecer la desviación estándar y media de la población\n",
    "mean, std = -0.545, 0.008\n",
    "\n",
    "# Calcule la media muestral\n",
    "sample_mean = a.mean()\n",
    "\n",
    "# Calcule el error estándar (desviación estándar de la población / número de población bajo el signo radical)\n",
    "se = std / np.sqrt(len(a))\n",
    "\n",
    "# Estadísticas Z\n",
    "Z = (sample_mean - mean) / se\n",
    "\n",
    "print(\"La estadística Z es {}\".format(Z))\n",
    "\n",
    "# Valor P\n",
    "P = 2 * stats.norm.sf(abs(Z)) # Aquí stats.norm.sf () devuelve el área en el lado derecho de Z, por lo que * 2 es la suma de las áreas en los lados izquierdo y derecho de Z\n",
    " \n",
    "print('El valor p es {}'.format(P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo miras de esta manera, P> 0.05, entonces tenemos que aceptar la hipótesis nula, lo que significa que este lote de leche cumple con el estándar y no se mezcla con agua.Pero esta pregunta es en realidad una prueba unilateral, Lo que debemos considerar es solo la parte de la leche cuya temperatura es más alta que la temperatura del punto de congelación, mientras que la leche cuya temperatura es más baja que la temperatura del punto de congelación es leche normal y no contiene agua.\n",
    "\n",
    "Cuanto más a la izquierda, más se acepta la hipótesis nula, lo que se necesita es que el valor P esté cerca de 1 cuando el área de la derecha está en el extremo izquierdo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ahora veremos intervalos de confianza pero sacare las definiciones de internet dado que no estan bien los metodos del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now simulate a dataset made of 100 numbers extracted from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8636363636363638"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3,1,2,3,1,2,4,5,2,4,5,2,4,6,2,4,1,2,3,4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see we want to calculate the 95% confidence interval of the mean value. Let’s calculate all the numbers we need according to the formula of confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.mean(x)\n",
    "#desviasion estandar\n",
    "s = np.std(x) \n",
    "dof = len(x)-1 \n",
    "confidence = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need the value of t. The function that calculates the inverse cumulative distribution is ppf. We need to apply the absolute value because the cumulative distribution works with the left tail, so the result would be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_crit = np.abs(t.ppf((1-confidence)/2,dof))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply the original formula to calculate the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.37221797102164283, 0.055143011885080584)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m-s*t_crit/np.sqrt(len(x)), m+s*t_crit/np.sqrt(len(x))) \n",
    "# (-0.14017768797464097, 0.259793719043611)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know it’s correct because the normal distribution has 0 mean, but if we don’t know anything about the population, we could say that, with 95% confidence, the expected value of the population lies between -0.14 and 0.26.\n",
    "We could have reached the same result using a bootstrap, which is unbiased. In this example, I create 1000 resamples of our dataset (with replacements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.27272727, 3.45454545])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [np.random.choice(x,size=len(x),replace=True).mean() for i in range(1000)] \n",
    "np.percentile(values,[100*(1-confidence)/2,100*(1-(1-confidence)/2)]) \n",
    "# array([-0.13559955, 0.26480175])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "## P HACKING\n",
    "\n",
    "def run_experiment():\n",
    "    #Aventar una moneda mil veces\n",
    "    return[np.random.random()<0.5 for _ in range(1000)]\n",
    "\n",
    "def reject_fairness(experiment):\n",
    "    #usar el 5% de significancia\n",
    "    num_heads = len([flip for flip in experiment if flip])\n",
    "    return num_heads < 469 or num_heads > 531\n",
    "np.random.seed(9)\n",
    "experiments = [run_experiment() for _ in range(1000)]\n",
    "num_rejections = len([experiment for experiment in experiments if reject_fairness(experiment)])\n",
    "\n",
    "print (num_rejections)\n",
    "\n",
    "#una prueba de hipotesis non es sustituto de el sentido común"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corriendo una A/B Test\n",
    "\n",
    "    Vamos a correr una prueba basada en dos tipos de comerciales para una bebida energetica desarrollada para Cientificos de Datos, mientras que la primera \"most datafulllly drink\" // y la segunda \"datum data balum\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimated_parameters(N,n):\n",
    "    p = n / N\n",
    "    sigma = math.sqrt(p * (1 -p)/N)\n",
    "    return p,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_b_test_stadistic(N_A,n_A,N_B,n_B):\n",
    "    p_A, sigma_A = estimated_parameters(N_A,n_A)\n",
    "    p_B, sigma_B = estimated_parameters(N_B,n_B)\n",
    "    return(p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si la estrategia A obtiene 200 clicks de 1,000 vistas y la estrategia B obtiene 180 de 1,000 vistas, la estadistica equivale a : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1403464899034472"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = a_b_test_stadistic(1000,200,1000,180)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscando ese valor en una tabla de distribucion normal en : https://www.socscistatistics.com/pvalues/normaldistribution.aspx <br>\n",
    "Con la configuracion de two tailed nos da como valor <br><br>\n",
    "##### The P-Value is $  0.254286.  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto significa que no hay mucha diferencia entre una campaña y otra y se puede continuar con ambas, sin ningnun cambio signficativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora veremos otra prueba de A/B Testing donde:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema de muestra : Identifique si un correo promocional de mejor apariencia lograría que más clientes se inscribieran en un club de entrega que cuesta $100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fines de junio, enviamos por correo contenido promocional a algunos de nuestros clientes para nuestro \"Club de entrega\". Inscribirse en el club cuesta dólares y les brindamos a los clientes entregas de comestibles gratuitas durante un año, a partir del 1 de julio.<br>\n",
    "Queríamos ver si un anuncio publicitario de mejor apariencia lograría que más clientes se suscribieran. Seleccionamos al azar 3 grupos, el primer grupo recibió el Mailer 1, una versión muy básica y económica que describía el trato, el segundo grupo recibió el Mailer 2, un mailer muy bonito y colorido impreso en cartón, y el tercer grupo fue el grupo de control y recibido al correo en absoluto.<br>\n",
    "Estamos muy seguros de que los clientes a los que se envió por correo se inscribieron a una tasa mucho más alta que el grupo de control... pero no estamos seguros de si existe una diferencia significativa entre la tasa de registro para el correo más barato y el más caro. . A primera vista, parece haber una tasa de registro ligeramente más alta para la versión costosa, pero antes de sacar conclusiones, queríamos que revisara los números.<br>\n",
    "### La tarea\n",
    "Evaluar si existe una diferencia entre el correo 1 y el correo 2 en términos de tasa de inscripción al club <br>\n",
    "### Las Hipótesis <br>\n",
    "null_hypothesis = No existe una relación entre el tipo de correo y la tasa de suscripción y son independientes.\n",
    "alternate_hypothesis = Existe una relación entre el tipo de remitente y la tasa de suscripción y que no son independientes.\n",
    "### La prueba utilizada <br>\n",
    "#### Prueba de chi-cuadrado\n",
    "##### El resultado\n",
    "chi2_estadística = 1,94<p>\n",
    "p_valor = 0,16<p>\n",
    "valor_critico = 3.84<p>\n",
    "Se mantiene la hipótesis nula. No existe una relación entre el tipo de correo y la tasa de registro. son independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140  19]\n",
      " [252 123]\n",
      " [209 127]]\n",
      "0.328 0.37797619047619047\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import chi2_contingency to compute for the chi-square statistics and the p-value for the particular hypothesis test\n",
    "# import chi2 to find the critical value based on the acceptance criteria\n",
    "from scipy.stats import chi2_contingency, chi2 \n",
    "\n",
    "# import data\n",
    "campaign_data = pd.read_excel(\"./recursos/grocery_database.xlsx\", sheet_name = \"campaign_data\")\n",
    "\n",
    "#Obtener frecuencias observadas\n",
    "\n",
    "# create a 2x2 matrix array\n",
    "# summarise to get our observed frequencies\n",
    "observed_values = pd.crosstab(campaign_data[\"mailer_type\"], campaign_data[\"signup_flag\"]).values\n",
    "print(observed_values)\n",
    "\n",
    "mailer1_signup_rate = 123 / (252 + 123) \n",
    "mailer2_signup_rate = 127 / (209 + 127)\n",
    "print(mailer1_signup_rate, mailer2_signup_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state hypotheses & set acceptance criteria\n",
    "null_hypothesis = \"There is no relationship between mailer type and signup rate. They are independent.\"\n",
    "alternate_hypothesis = \"There is a relationship between mailer type and signup rate. They are not independent.\"\n",
    "acceptance_criteria = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.85054342506307 2.7058308848098242e-08\n",
      "5.991464547107979\n"
     ]
    }
   ],
   "source": [
    "# calculate expected frequencies & chi square statistic\n",
    "chi2_statistic, p_value, dof, expected_values = chi2_contingency(observed_values, correction = False)\n",
    "print(chi2_statistic, p_value)\n",
    "\n",
    "# find the critical value for our test\n",
    "critical_value = chi2.ppf(1 - acceptance_criteria, dof)\n",
    "print(critical_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de los resultados<p>\n",
    "El problema de muestra había evaluado la diferencia en la tasa de inscripción al club entre dos correos diferentes que se enviaron. Y en base a los datos proporcionados y usando la prueba de chi-cuadrado para la independencia, ahora puedo recomendar a ABC Grocery y tal vez a su departamento de marketing que pueden dejar de enviar un anuncio por correo de apariencia costosa o incluso un anuncio por correo simple para ahorrar costos, ya que no ayuda. en lograr que los clientes se inscriban en la promoción del club de entrega."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12e7b2db913c7cced4d5bf71ce365c438f2053887e824f813caa9208ccef4b13"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
